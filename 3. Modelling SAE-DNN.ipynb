{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4fe091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 14:44:25.834301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-01 14:44:25.834338: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fdadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df_pubchem = pd.read_csv('dataset/final/df_pubchem_rapi.csv')\n",
    "\n",
    "#drop CID_senyawa\n",
    "df_pubchem = df_pubchem.drop(['CID_senyawa'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc4dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pubchem\n",
    "Y = pd.read_csv('dataset/final/kelas_data.csv')\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5434d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b927ad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[1, 0, 0]</th>\n",
       "      <th>[0, 1, 0]</th>\n",
       "      <th>[0, 0, 1]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>4477</td>\n",
       "      <td>319</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       [1, 0, 0]  [0, 1, 0]  [0, 0, 1]\n",
       "Class       4477        319         51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_kelas_pubchem = pd.read_csv('dataset/data_model/pubchem_final.csv')\n",
    "# df_kelas_pubchem['Class'].value_counts().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a235ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4847, 881)\n",
      "(4847, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_pubchem.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b78c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "445e488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import IterativeStratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "354b084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(123)\n",
    "cv = IterativeStratification(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c86c13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterativeStratification(n_splits=5, order=1, random_state=None,\n",
       "            sample_distribution_per_fold=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b498ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_ix, test_ix in cv.split(X,Y):\n",
    "    #Bagi data menjadi train, test\n",
    "    X_train, X_test = X.iloc[train_ix,:], X.iloc[test_ix,:]\n",
    "    y_train, y_test = Y[train_ix], Y[test_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7288a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>871</th>\n",
       "      <th>872</th>\n",
       "      <th>873</th>\n",
       "      <th>874</th>\n",
       "      <th>875</th>\n",
       "      <th>876</th>\n",
       "      <th>877</th>\n",
       "      <th>878</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3878 rows × 881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  871  872  873  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "4841  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "4842  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "4843  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "4844  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "4846  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      874  875  876  877  878  879  880  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "4841  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4842  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4843  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4844  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4846  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3878 rows x 881 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abe7451e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f81745dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 10:43:53.996231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-30 10:43:53.996290: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-30 10:43:53.996334: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fadilrisdian-X455LAB): /proc/driver/nvidia/version does not exist\n",
      "2022-06-30 10:43:53.997214: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# define model dengan bobot SAE. Jika tidak memakai bobot SAE, sae_weights = None\n",
    "model = dnn_model(xt = X_train, sae_weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63bd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf06ef4",
   "metadata": {},
   "source": [
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da44be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27338/4292856852.py:25: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import time\n",
    "# Iterative Stratification untuk cross validation multilabel\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "\n",
    "#Import Tensorflow dan extension\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import  EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, Adagrad, SGD, RMSprop, Adadelta\n",
    "\n",
    "#Import keras tuner dan metrics untuk tuning parameter\n",
    "import kerastuner as kt\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
    "from sklearn import metrics\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac0d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifikasi IterativeStratification agar hasil random data tetap sama\n",
    "\n",
    "def new_init(self, n_splits=3, order=1, sample_distribution_per_fold = None, random_state=None):\n",
    "\n",
    "                  self.order = order\n",
    "                  if random_state is not None:\n",
    "                      do_shuffle = True\n",
    "                  else:\n",
    "                      do_shuffle = False\n",
    "                  super(\n",
    "                      IterativeStratification,\n",
    "                      self).__init__(n_splits,\n",
    "                                     shuffle=do_shuffle,\n",
    "                                     random_state=random_state)\n",
    "                  if sample_distribution_per_fold:\n",
    "                      self.percentage_per_fold = sample_distribution_per_fold\n",
    "                  else:\n",
    "                      self.percentage_per_fold = [1 / float(self.n_splits) for _ in range(self.n_splits)]\n",
    "    \n",
    "IterativeStratification.__init__ = new_init\n",
    "# cv = IterativeStratification(n_splits=5, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54bc07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi model SAE\n",
    "def sae_model(xt, xv = None, EPOCHS = 100,BATCH_SIZE = 32, opt = \"adam\",\n",
    "              hl_node = 1024, lr = 0.01,af = \"relu\",num_layers = 3, do=0.5, fr_node = 0.5,\n",
    "              verbose = 0,return_fe = False):\n",
    "  #Setting result placeholders\n",
    "  xt_ae = [] ;xv_ae = [] ; w_ae = []\n",
    "  #If validation set is not present, use train set as validation set\n",
    "  if xv is None :\n",
    "    xv = xt.copy()\n",
    "  opt = tf.keras.optimizers.get(opt) #Set optimizer\n",
    "  K.set_value(opt.learning_rate, lr) #Set learning rate\n",
    "\n",
    "  #Stacked Autoencoder architecture\n",
    "  for n_layers in range(num_layers):\n",
    "    #Autoencoder\n",
    "    inp = Input(shape=(xt.shape[1],))\n",
    "    #Apply Dropout\n",
    "    hidden_layer = Dropout(do)(inp)\n",
    "    #Layer encoder (jumlah layer sesuai dengan n_layers)\n",
    "    enc = Dense(int(hl_node*(fr_node**n_layers)), activation = af)(hidden_layer)  \n",
    "    #Layer Decoder\n",
    "    dec = Dense(xt.shape[1],activation=\"linear\")(enc)\n",
    "    ae = Model(inp, dec)\n",
    "    #Compile model\n",
    "    ae.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    #EarlyStop jika sudah konvergen \n",
    "    es = EarlyStopping(monitor='val_loss', patience=15, verbose=verbose)\n",
    "    #Latih model\n",
    "    ae.fit(xt, xt, \n",
    "           epochs=EPOCHS,batch_size=BATCH_SIZE, \n",
    "           shuffle=True, callbacks = [es] , verbose = verbose,\n",
    "           validation_data = (xv,xv))\n",
    "    #Ekstrak Feature extraction\n",
    "    fe = Model(ae.input, enc)\n",
    "    #Simpan data hasil latih\n",
    "    xt = fe.predict(xt) ; xt_ae.append(xt)\n",
    "    xv = fe.predict(xv) ; xv_ae.append(xv)\n",
    "    #Simpan bobot hasil latih SAE\n",
    "    w_ae.append([layer_name for layer_name in ae.layers if \"dense\" in layer_name.name][0].get_weights())\n",
    "    if verbose:\n",
    "      print(\"Layer {} trained\".format(n_layers+1))\n",
    "\n",
    "  return (w_ae,xv) if return_fe else w_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4fea689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi DNN\n",
    "\n",
    "# kelas output 3\n",
    "# n_outputs = 3\n",
    "\n",
    "def dnn_model(xt, n_outputs = 7, sae_weights = None, EPOCHS = 100,BATCH_SIZE = 32, opt = \"adam\",\n",
    "              hl_node = 1024, lr = 0.01,af = \"relu\",num_layers = 3, do=0.5, fr_node = 0.5):\n",
    "  opt = tf.keras.optimizers.get(opt) #Set optimizer\n",
    "  K.set_value(opt.learning_rate, lr) #Set learning rate\n",
    "  \n",
    "  #Model architecture\n",
    "  input_layer = Input(shape=(xt.shape[1],))\n",
    "  hidden_layer = BatchNormalization()(input_layer)\n",
    "  hidden_layer = Dropout(do)(hidden_layer)\n",
    "\n",
    "#Set jumlah hidden layer\n",
    "  for n_layers in range(num_layers):\n",
    "    hidden_layer = Dense(int(hl_node*(fr_node**n_layers)), activation = af)(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(do)(hidden_layer)\n",
    "  output_layer = Dense(n_outputs, activation = 'sigmoid')(hidden_layer)\n",
    "\n",
    "#latih model\n",
    "  dnn = Model(input_layer, output_layer)\n",
    "\n",
    "  #Latih model DNN dengan bobot SAE (jika bobot ada)\n",
    "  if sae_weights is not None:\n",
    "    weights = sae_weights\n",
    "    dnn_dense = [layer_name for layer_name in dnn.layers if \"dense\" in layer_name.name]\n",
    "    for weight_from,weight_to in list(zip(weights,dnn_dense)):\n",
    "      weight_to.set_weights(weight_from)\n",
    "\n",
    "#Compile model\n",
    "  dnn.compile(optimizer=opt, loss='binary_crossentropy', metrics = [tf.keras.metrics.BinaryAccuracy(),\n",
    "               tf.keras.metrics.Precision(),\n",
    "               tf.keras.metrics.Recall()],\n",
    "               )\n",
    "  return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d0c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(123)\n",
    "cv = IterativeStratification(n_splits=5, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85da6ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding sae weights....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 14:46:24.181140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-01 14:46:24.181193: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-01 14:46:24.181234: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fadilrisdian-X455LAB): /proc/driver/nvidia/version does not exist\n",
      "2022-07-01 14:46:24.182036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 1s 4ms/step\n",
      "177/177 [==============================] - 1s 4ms/step\n",
      "177/177 [==============================] - 1s 3ms/step\n",
      "177/177 [==============================] - 1s 3ms/step\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "done, processing time: 182.11906552314758\n",
      "36/36 [==============================] - 0s 7ms/step\n",
      "CV number:  0\n",
      "accuracy of :>0.867\n",
      "F1 of :>0.887\n",
      "Precision of :>0.894\n",
      "Recall of :>0.890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV number:  1\n",
      "accuracy of :>0.891\n",
      "F1 of :>0.912\n",
      "Precision of :>0.919\n",
      "Recall of :>0.915\n",
      "36/36 [==============================] - 0s 6ms/step\n",
      "CV number:  2\n",
      "accuracy of :>0.880\n",
      "F1 of :>0.900\n",
      "Precision of :>0.912\n",
      "Recall of :>0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 6ms/step\n",
      "CV number:  3\n",
      "accuracy of :>0.883\n",
      "F1 of :>0.914\n",
      "Precision of :>0.922\n",
      "Recall of :>0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 8ms/step\n",
      "CV number:  4\n",
      "accuracy of :>0.879\n",
      "F1 of :>0.906\n",
      "Precision of :>0.916\n",
      "Recall of :>0.907\n",
      "waktu proses 1499.7519092559814\n",
      "Accuracy array: [0.8668430335097002, 0.8909410729991205, 0.879646017699115, 0.8830357142857143, 0.8786536758193091]\n",
      "F1 array: [0.8865289325606786, 0.9117458667590593, 0.9004003371260009, 0.9135376726448154, 0.9063562360285125]\n",
      "Precision array: [0.8935185185185185, 0.9194580558696653, 0.9121533923303835, 0.921547619047619, 0.9164452317685265]\n",
      "Recall array: [0.8901381540270429, 0.9147610671357375, 0.8990707964601771, 0.9174574829931972, 0.9065249483318571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Train SAE-DNN\n",
    "#Variabel untuk simpan hasil\n",
    "acc_results = list()\n",
    "f1_results = list()\n",
    "prec_results = list()\n",
    "rec_results = list()\n",
    "# define evaluation procedure\n",
    "np.random.seed(123)\n",
    "#Inisialisasi CV\n",
    "cv = IterativeStratification(n_splits=5, random_state = 123)\n",
    "#Latih SAE \n",
    "print(\"finding sae weights....\")\n",
    "ti0 = time.time()\n",
    "sae_weights = sae_model(xt = X)\n",
    "ti1 = time.time()\n",
    "print('done, processing time:', ti1-ti0)\n",
    "i=0\n",
    "t0 = time.time()\n",
    "#Mulai latih DNN dengan bobot hasil SAE untuk tiap CV\n",
    "for train_ix, test_ix in cv.split(X,Y):\n",
    "    #Bagi data menjadi train, test\n",
    "    X_train, X_test = X.iloc[train_ix,:], X.iloc[test_ix,:]\n",
    "    y_train, y_test = Y[train_ix], Y[test_ix]\n",
    "    # define model dengan bobot SAE. Jika tidak memakai bobot SAE, sae_weights = None\n",
    "    model = dnn_model(xt = X_train, sae_weights = sae_weights)\n",
    "    \n",
    "    # latih model\n",
    "    model.fit(X_train, y_train, verbose=False, epochs=100)\n",
    "    \n",
    "    # Prediksi test \n",
    "    yhat = model.predict(X_test)\n",
    "    # Bulatkan hasil prediksi (probabilitas)\n",
    "    yhat = yhat.round()\n",
    "    # Hitung metrik\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    f1 = f1_score(y_test, yhat, average='samples')\n",
    "    prec = precision_score(y_test, yhat, average='samples')\n",
    "    rec = recall_score(y_test, yhat, average='samples')\n",
    "    # Simpan hasil\n",
    "    print(\"CV number: \", i)\n",
    "    print('accuracy of :>%.3f' % acc)\n",
    "    print('F1 of :>%.3f' % f1)\n",
    "    print('Precision of :>%.3f' % prec)\n",
    "    print('Recall of :>%.3f' % rec)\n",
    "    acc_results.append(acc)\n",
    "    f1_results.append(f1)\n",
    "    prec_results.append(prec)\n",
    "    rec_results.append(rec)\n",
    "    i=i+1\n",
    "t1 = time.time()\n",
    "print(\"waktu proses\", t1-t0)\n",
    "print(\"Accuracy array:\", acc_results)\n",
    "print(\"F1 array:\", f1_results)\n",
    "print(\"Precision array:\", prec_results)\n",
    "print(\"Recall array:\", rec_results)\n",
    "#save model\n",
    "model.save(\"sae_dnn_awal.h5\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb000299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 6ms/step\n",
      "CV number:  0\n",
      "accuracy of :>0.872\n",
      "F1 of :>0.886\n",
      "Precision of :>0.895\n",
      "Recall of :>0.884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 5ms/step\n",
      "CV number:  0\n",
      "accuracy of :>0.892\n",
      "F1 of :>0.914\n",
      "Precision of :>0.926\n",
      "Recall of :>0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step\n",
      "CV number:  0\n",
      "accuracy of :>0.879\n",
      "F1 of :>0.896\n",
      "Precision of :>0.905\n",
      "Recall of :>0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step\n",
      "CV number:  0\n",
      "accuracy of :>0.897\n",
      "F1 of :>0.921\n",
      "Precision of :>0.932\n",
      "Recall of :>0.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 7ms/step\n",
      "CV number:  0\n",
      "accuracy of :>0.869\n",
      "F1 of :>0.894\n",
      "Precision of :>0.900\n",
      "Recall of :>0.897\n",
      "waktu proses 1664.6080338954926\n",
      "Accuracy array: [0.8722271517302573, 0.8915770609318996, 0.8791593695271454, 0.8966131907308378, 0.868766404199475]\n",
      "F1 array: [0.8855617910631219, 0.9143703419241053, 0.896134600950713, 0.9209492428743766, 0.8937966087572387]\n",
      "Precision array: [0.8952528837622006, 0.9256869772998805, 0.9048453006421484, 0.9323975044563281, 0.8995625546806649]\n",
      "Recall array: [0.8839988169180716, 0.9123655913978495, 0.8952276707530649, 0.9199219081572023, 0.8973753280839896]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fadilrisdian/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Train DNN saja\n",
    "acc_results2 = list()\n",
    "f1_results2 = list()\n",
    "prec_results2 = list()\n",
    "rec_results2 = list()\n",
    "n_inputs, n_outputs = X.shape[1], 7\n",
    "# define evaluation procedure\n",
    "# cv = IterativeStratification(n_splits=5, random_state = 123)\n",
    "i=0\n",
    "# enumerate folds\n",
    "t0 = time.time()\n",
    "for train_ix, test_ix in cv.split(X,Y):\n",
    "    # prepare data\n",
    "    X_train, X_test = X.iloc[train_ix,:], X.iloc[test_ix,:]\n",
    "    y_train, y_test = Y[train_ix], Y[test_ix]\n",
    "    # define model tanpa bobot SAE\n",
    "    model = dnn_model(xt = X_train, sae_weights = None)\n",
    "    # fit model\n",
    "    model.fit(X_train, y_train, verbose=False, epochs=100)\n",
    "    # make a prediction on the test set\n",
    "    yhat = model.predict(X_test)\n",
    "    # round probabilities to class labels\n",
    "    yhat = yhat.round()\n",
    "    # calculate metrics\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    f1 = f1_score(y_test, yhat, average='samples')\n",
    "    prec = precision_score(y_test, yhat, average='samples')\n",
    "    rec = recall_score(y_test, yhat, average='samples')\n",
    "    # store result\n",
    "    print(\"CV number: \", i)\n",
    "    print('accuracy of :>%.3f' % acc)\n",
    "    print('F1 of :>%.3f' % f1)\n",
    "    print('Precision of :>%.3f' % prec)\n",
    "    print('Recall of :>%.3f' % rec)\n",
    "    acc_results2.append(acc)\n",
    "    f1_results2.append(f1)\n",
    "    prec_results2.append(prec)\n",
    "    rec_results2.append(rec)\n",
    "t1 = time.time()\n",
    "print(\"waktu proses\", t1-t0)\n",
    "print(\"Accuracy array:\", acc_results2)\n",
    "print(\"F1 array:\", f1_results2)\n",
    "print(\"Precision array:\", prec_results2)\n",
    "print(\"Recall array:\", rec_results2)\n",
    "#save model\n",
    "model.save(\"dnn_only_NewData40k.h5\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa19db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "SAE-DNN PERFORMANCE\n",
      "Accuracy    : 0.87982±0.008\n",
      "F1 Score    : 0.90371±0.010\n",
      "Precision   : 0.91262±0.010\n",
      "Recall      : 0.90559±0.010\n",
      "===================================\n",
      "===================================\n",
      "DNN ONLY PERFORMANCE\n",
      "Accuracy    : 0.88167±0.011\n",
      "F1 Score    : 0.90216±0.013\n",
      "Precision   : 0.91155±0.015\n",
      "Recall       : 0.90178±0.013\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "print('===================================')\n",
    "print('SAE-DNN PERFORMANCE')\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(acc_results), np.std(acc_results)))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(f1_results), np.std(f1_results)))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(prec_results), np.std(prec_results)))\n",
    "print('Recall      : {0:.5f}±{1:.3f}'.format(np.mean(rec_results), np.std(rec_results)))\n",
    "print('===================================')\n",
    "print('===================================')\n",
    "print('DNN ONLY PERFORMANCE')\n",
    "print('Accuracy    : {0:.5f}±{1:.3f}'.format(np.mean(acc_results2), np.std(acc_results2)))\n",
    "print('F1 Score    : {0:.5f}±{1:.3f}'.format(np.mean(f1_results2), np.std(f1_results2)))\n",
    "print('Precision   : {0:.5f}±{1:.3f}'.format(np.mean(prec_results2), np.std(prec_results2)))\n",
    "print('Recall       : {0:.5f}±{1:.3f}'.format(np.mean(rec_results2), np.std(rec_results2)))\n",
    "print('===================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1ada8",
   "metadata": {},
   "source": [
    "# Tuning Parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a02e45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "242c1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi model untuk tuning\n",
    "def build_model(hp):\n",
    "    #Isi parameter yang akan dituning\n",
    "    params = {\n",
    "              'hl_node' : hp.Choice('units',values = [1500,1600,1700,1800]),\n",
    "              'af' : hp.Choice('activation',values = [\"relu\"]),\n",
    "              'lr' : hp.Choice('learning_rate',values=[x for x in np.linspace(0.01,0.1,10)]),\n",
    "              'opt' : hp.Choice('optimizer',values=[\"adam\", \"adagrad\"]),\n",
    "              'num_layers' : hp.Choice('num_layers',values=[2,3,4,5]),\n",
    "              'do' : hp.Choice('dropout_rate',values=[0.5,0.6,0.7,0.8]),\n",
    "              'fr_node' : hp.Choice('fraction_node',values=[0.5,0.66,0.75])\n",
    "              }\n",
    "    #Latih model SAE\n",
    "    sae_weights = sae_model(xt = X, xv = X_train, EPOCHS= 100,**params)\n",
    "    #Latih model DNN dengan bobot SAE\n",
    "    sae_dnn = dnn_model(X_train, sae_weights=sae_weights, EPOCHS= 100,**params)\n",
    "    return sae_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf03b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 4ms/step\n",
      "122/122 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m stop_early \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_recall\u001b[39m\u001b[38;5;124m'\u001b[39m,patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Fungsi Bayesian Optimization di Keras Tuner.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mBayesianOptimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Metrik yang dicari optimalnya\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_recall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Jumlah percobaan\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Folder simpan hasil tuning\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/fadilrisdian/skripsi-fadil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msae_dnn_tuning_bayesFiltered40k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Jalankan Keras Tuner u\u001b[39;00m\n\u001b[1;32m     13\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),callbacks\u001b[38;5;241m=\u001b[39m[stop_early])\n",
      "File \u001b[0;32m~/anaconda3/envs/model/lib/python3.10/site-packages/keras_tuner/tuners/bayesian.py:460\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    437\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    448\u001b[0m ):\n\u001b[1;32m    449\u001b[0m     oracle \u001b[38;5;241m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    450\u001b[0m         objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    451\u001b[0m         max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m         allow_new_entries\u001b[38;5;241m=\u001b[39mallow_new_entries,\n\u001b[1;32m    459\u001b[0m     )\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBayesianOptimization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scipy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install scipy before using the `BayesianOptimization`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/model/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:110\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_size \u001b[38;5;241m=\u001b[39m max_model_size\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[0;32m~/anaconda3/envs/model/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:103\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m logger\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display \u001b[38;5;241m=\u001b[39m tuner_utils\u001b[38;5;241m.\u001b[39mDisplay(oracle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tuner_fname()):\n\u001b[1;32m    106\u001b[0m     tf\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReloading Tuner from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tuner_fname())\n\u001b[1;32m    108\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/model/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:132\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m scopes_once_active \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Update the recored scopes.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conditions \u001b[38;5;129;01min\u001b[39;00m hp\u001b[38;5;241m.\u001b[39mactive_scopes:\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m      4\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhl_node\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m,values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1500\u001b[39m,\u001b[38;5;241m1600\u001b[39m,\u001b[38;5;241m1700\u001b[39m,\u001b[38;5;241m1800\u001b[39m]),\n\u001b[1;32m      6\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maf\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m,values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr_node\u001b[39m\u001b[38;5;124m'\u001b[39m : hp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfraction_node\u001b[39m\u001b[38;5;124m'\u001b[39m,values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.66\u001b[39m,\u001b[38;5;241m0.75\u001b[39m])\n\u001b[1;32m     12\u001b[0m           }\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Latih model SAE\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m sae_weights \u001b[38;5;241m=\u001b[39m \u001b[43msae_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#Latih model DNN dengan bobot SAE\u001b[39;00m\n\u001b[1;32m     16\u001b[0m sae_dnn \u001b[38;5;241m=\u001b[39m dnn_model(X_train, sae_weights\u001b[38;5;241m=\u001b[39msae_weights, EPOCHS\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36msae_model\u001b[0;34m(xt, xv, EPOCHS, BATCH_SIZE, opt, hl_node, lr, af, num_layers, do, fr_node, verbose, return_fe)\u001b[0m\n\u001b[1;32m     27\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#Latih model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m       \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mxv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#Ekstrak Feature extraction\u001b[39;00m\n\u001b[1;32m     34\u001b[0m fe \u001b[38;5;241m=\u001b[39m Model(ae\u001b[38;5;241m.\u001b[39minput, enc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_recall',patience = 25)\n",
    "# Fungsi Bayesian Optimization di Keras Tuner.\n",
    "tuner = BayesianOptimization(build_model,\n",
    "    # Metrik yang dicari optimalnya\n",
    "    objective= kt.Objective(\"val_recall\", direction=\"max\"), \n",
    "    # Jumlah percobaan\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    # Folder simpan hasil tuning\n",
    "    directory='/home/fadilrisdian/skripsi-fadil',\n",
    "    project_name='sae_dnn_tuning_bayesFiltered40k', overwrite = True)\n",
    "#Jalankan Keras Tuner u\n",
    "tuner.search(X_train, y_train, epochs=100, validation_data=(X_test, y_test),callbacks=[stop_early])\n",
    "#Tampilkan hasil terbaik\n",
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
